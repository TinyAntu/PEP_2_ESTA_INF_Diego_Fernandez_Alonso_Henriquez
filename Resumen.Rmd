---
title: "Codigo util"
output: html_document
date: "2024-12-26"
---

# Alternativas para analisis de datos problematicos

## Alternativa robusta a las medias

Para cuando contamos con valores extremos atipicos podemos utilizar la media Windorizada la caul se puede calcular con winmean  del paquete WRS2:

```{r}
library(WRS2)
#Ignora el 20% de los datos en cada extremo
x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100)
winmean(x, tr = 0.2)
```
## Prueba de Yuen para 2 muestras independientes

Alternativa a T Student para muestras independientes es utilizada cuando las varianzas de ambas muestras son muy diferentes o los tamaños de las muestras son muy dispares. No se recomienda esto si es que el nivel de truncamiento esta cerca de 0.5.

H0: Medias iguales

Ha: Medias diferentes

La funcion es yuenbt del paquete WRS2 (formula es : Variable dependiente ~ Variable independiente):

```{r}
library(WRS2)
library(ggpubr)

#Ejemplo

a <- c(25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0
       ,26.1,26.2,26.3,26.4,26.5,26.6,26.7,26.8,26.9,27.0,
       27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.4,
       28.5,29.0,29.8,30.2,31.8,31.9,33.3,33.7)

b <- c(24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,24.9,25.0,
       25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0,26.1,
       26.2,26.3,27.1,27.2,
       27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.1,28.2,28.3,30.0,30.1,30.2,30.3)

tiempo <- c(a,b)
algoritmo  <- c(rep("A",length(a)),rep("B",length(b)))
datos <- data.frame(tiempo,algoritmo)

#Comprobar normalidad
#Antes del truncamientio
g <- ggqqplot(datos, x = "tiempo", facet.by = "algoritmo",
             palette = c("blue", "red"), color ="algoritmo")

print(g)

#Poda
gamma <- 0.2

n_a <- length(a)
n_b <- length(b)

poda_a <- n_a * gamma
poda_b <- n_b * gamma

a_truncada <- a[poda_a:(n_a - poda_a)]
b_truncada <- b[poda_b:(n_b - poda_b)]

tiempo <- c(a_truncada,b_truncada)
algoritmo <- c(rep("A",length(a_truncada)),rep("B",length(b_truncada)))
datos_truncados <- data.frame(tiempo,algoritmo)

#Despues del truncamientio 
g <- ggqqplot(datos_truncados, x = "tiempo", facet.by = "algoritmo",
              palette = c("blue", "red"), color = "algoritmo")

print(g)

#Prueba de Yuen
yuen(tiempo ~ algoritmo, data = datos_truncados, tr = gamma)


```
Otra opcion es pb2gen que utiliza boostraping para aplicar la prueba de yuen usando otras medidas robustas de tendencia central.

```{r}
library(WRS2)


#Ejemplo

a <- c(25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0
       ,26.1,26.2,26.3,26.4,26.5,26.6,26.7,26.8,26.9,27.0,
       27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.4,
       28.5,29.0,29.8,30.2,31.8,31.9,33.3,33.7)

b <- c(24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,24.9,25.0,
       25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0,26.1,
       26.2,26.3,27.1,27.2,
       27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.1,28.2,28.3,30.0,30.1,30.2,30.3)

tiempo <- c(a,b)
algoritmo  <- c(rep("A",length(a)),rep("B",length(b)))
datos <- data.frame(tiempo,algoritmo)

bootstrap <- 999

set.seed(135)

prueba_media <- pb2gen(tiempo ~ algoritmo, data = datos, est = "mean", nboot = bootstrap)

cat("Resultado al utilizar media como estimador \n")
print(prueba_media)

set.seed(135)

prueba_mediana <- pb2gen(tiempo ~ algoritmo, data = datos, est = "median", nboot = bootstrap)

cat("Resultado al utilizar mediana como estimador \n")
print(prueba_mediana)

```
## Prueba de Yuen para 2 muestras pareadas

```{r}
library(WRS2)


#Ejemplo

a <- c(25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0
       ,26.1,26.2,26.3,26.4,26.5,26.6,26.7,26.8,26.9,27.0,
       27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.4,
       28.5,29.0,29.8,30.2,31.8,31.9,33.3,33.7)

b <- c(24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,24.9,25.0,
       25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0,26.1,
       26.2,26.3,27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0
       ,28.1,28.2,28.3,30.0,30.1,30.2)

#Aplicar prueba para muestras pareadas

gama <- 0.2
yuend(a, b, tr = gamma)

```
## Comparaciones de una via para multiples grupos independientes

El paquete WRS2 ofrece diferentes alternativas a ANOVA de una via para muestras independientes es util para cuando los tamaño de las muestrasn son muy diferentes o no se cumple la homocedasticidad.

Para esto se utiliza t1way que es un procedimiento como el ANOVA pero con medias truncadas y para el analisis PostHoc es con lincon, para posthoc con bootstrap en con mcppb20.

Otra opcion es med1way que realiza un ANOVA iterativo pero este no cuenta con analisis PostHoc

```{r}
library(WRS2)

#Matriz de datos

a <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 26.6, 26.7, 26.7, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7)

b <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.3, 25.4, 25.7, 25.7, 25.7, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)

c <- c(24.5, 24.5, 24.5, 24.5, 24.5, 24.5, 24.6, 24.6, 24.6, 24.6, 24.7, 24.7, 24.7, 24.7, 24.8, 25.0, 25.0, 25.0, 25.2, 25.2, 25.2, 25.5, 25.5, 25.7, 25.9, 26.2, 26.5, 26.5, 26.7, 27.0, 29.2, 29.9, 30.1)

tiempo <- c(a, b, c)
algoritmo <- c(rep("A", length(a)), rep("B", length(b)), rep("C", length(c)))
datos <- data.frame(tiempo, algoritmo)

# Fijar nivel de significación.
alfa <- 0.05

# Comparar los diferentes algoritmos usando medias truncadas.
cat("Comparación entre grupos usando medias truncadas\n\n")
gamma <- 0.2

set.seed(666)

medias_truncadas <- t1way(tiempo ~ algoritmo, data = datos, tr = gamma, alpha = alfa)


print(medias_truncadas)

set.seed(666)
muestras <- 999

cat("Post hoc iterativo\n\n")

post_hoc <- lincon(tiempo ~ algoritmo, data = datos, tr = gamma, alpha = alfa)

print(post_hoc)

cat("Post hoc con bootstrap\n\n")
set.seed(666)
boot <- t1waybt(tiempo ~ algoritmo, data = datos, tr = gamma, nboot = muestras, alpha = alfa)

print(boot)


set.seed(666)
post_hoc_2 <- mcppb20(tiempo ~ algoritmo, data = datos, tr = gamma, nboot = muestras, alpha = alfa)

print(post_hoc_2)

```
## Comparaciones de una via para multiples grupos correlacionados

Es util cuando los datos violan la condicion de esferecidad 

Para esto la funcion es rmanova y para el post hoc es rmmcp. Aparte para incorporar bootstraping tenemos rmanovab y el post hoc seria con pairdepb

```{r}
library(WRS2)
library(tidyverse)

# Construir data frame.
X <- c(32.0, 32.0, 32.0, 32.0, 32.1, 32.1, 32.1, 32.2, 32.3, 32.3, 32.5,
       32.7, 32.7, 32.7, 33.1, 33.4, 33.9, 34.1, 34.2, 34.5, 36.0, 36.6, 
       36.7, 37.2, 38.0)

Y <- c(33.0, 33.0, 33.0, 33.0, 33.3, 33.3, 33.3, 33.3, 33.5, 
       33.6, 33.7, 33.9, 33.9, 34.2, 34.2, 34.3, 34.3, 34.3, 34.4, 34.4, 
       34.5, 34.6, 36.4, 38.9, 40.2)

Z <- c(32.0, 32.2, 32.5, 32.6, 32.7, 32.7, 32.7, 33.0, 33.2, 33.4, 33.6, 
       33.6, 33.9, 34.1, 34.2, 34.4, 34.4, 34.5, 34.6, 34.7, 36.3, 36.6, 
       36.7, 38.9, 39.2)

instancia <- 1:length(X)
datos <- data.frame(instancia, X, Y, Z)

# Llevar data frame a formato largo
datos_largo <- datos %>% pivot_longer( c("X", "Y", "Z"), names_to = "algoritmo", values_to = "tiempo")

# Convertir columna algoritmo en factor
datos_largo[["algoritmo"]] <- factor(datos_largo[["algoritmo"]])

# Fijar nivel de significación.
alfa <- 0.05

# Aplicar alternativa robusta a ANOVA de una vía con muestras correlacionadas
gamma <- 0.2

prueba <- rmanova(y = datos_largo[["tiempo"]], groups = datos_largo[["algoritmo"]], blocks = datos_largo[["instancia"]], tr = gamma)

print(prueba)

post_hoc <- rmmcp(y = datos_largo[["tiempo"]], groups = datos_largo[["algoritmo"]], blocks = datos_largo[["instancia"]], tr = gamma, alpha = alfa)

print(post_hoc)

```


# Remuestreo

Es una buena alternativa para cuando cuando se necesita inferir sobre parametros distintos de la media o proporcion o bien cuando no se cumplen las condicionees necesarias de alguna prueba.
## Bootstraping

### Bootstraping para una muestra

Para esto tenemos boot el cual genera la distribucion de bootstrap y boo.ci que calcula los intervalos de confianza. Otra opcion que no requiere la implementacion de funcion de calculo de medias es bootES.

```{r}
library(boot)
library(bootES)

#Muestra inicial para el calculo de la media e histograma

muestra <- c(79,75,84,75,94,82,76,90,79,80)
datos <- data.frame(muestra)

#Cantidad de remuestreos
B <- 2000
alfa <- 0.05

# Funcion para calcular el estadistico: media de la muestra
media <- function(valores, i){
  mean(valores[i])
}

#Contruir la distribuccion con boot
set.seed(432)
distribucion_b <- boot(muestra, statistic = media, R = B)

#Grafico de la distribucion de boostrap
cat("Distribución de bootstrap con Boot\n")
print(distribucion_b)
plot(distribucion_b)

#Intervalo de confianza

ics <- boot.ci(distribucion_b, type = c("norm", "perc", "bca"), conf = 1 - alfa)

cat("Intervalos de confianza con Boot.ci\n")
print(ics)

#Contruir la distribuccion con bootES
set.seed(432)
distribucion_b_es <- bootES(muestra,R = B, ci.type="bca", ci.conf = 1-alfa, plot = TRUE)

#Bootstrap con BootES
cat("Distribución de bootstrap con BootES\n")
print(distribucion_b_es)

```
Pero para concluir sobre esta hay que desplazarla para que sea representativa de la hipotesis nula

```{r}
library(boot)
library(bootES)

#Muestra inicial para el calculo de la media e histograma

muestra <- c(79,75,84,75,94,82,76,90,79,80)
valor_observado <- mean(muestra)
datos <- data.frame(muestra)

#Cantidad de remuestreos
B <- 2000
alfa <- 0.05

# Funcion para calcular el estadistico: media de la muestra
media <- function(valores, i){
  mean(valores[i])
}

#Contruir la distribuccion con boot
set.seed(432)
distribucion_b <- boot(muestra, statistic = media, R = B)

#Desplazar la distribucion bootstrap para que se centre en el valor nulo
# RECORDAR QUE ESTO ES PARA H0 = X, Ha > X
valor_nulo <- 75
desplazamiento <- mean(distribucion_b[["t"]]) - valor_nulo
distribucion_nula <- distribucion_b[["t"]] - desplazamiento

#El valor de P

p <- (sum(distribucion_nula > valor_observado)+ 1) / (B+1)
cat("Valor de P: ", p, "\n")

```
Otra opcion es ver si el valor nulo esta dentro del intervalo de confianza ya que si no lo esta sabemos que la H0 no se cumple

### Bootstraping para dos muestras independientes

Se hace uso del paquete simpleboot con la funcion two.boot

```{r}
library(boot)
library(ggpubr)
library(simpleboot)

# Ingresar datos originales
hombres <- c(1.3, 1.5, 1.6, 1.7, 1.7, 1.9, 2.3, 2.4, 2.6, 2.6, 2.7,
             2.8, 3.2, 3.7, 4.1, 4.4, 4.5, 4.8, 5.2, 5.2, 5.3, 5.5,
             5.5, 5.6, 5.6, 5.7, 5.7)

mujeres <- c(3.5, 3.6, 3.8, 4.3, 4.5, 4.5, 4.9, 5.1, 5.3, 5.3, 5.5,
             5.8, 6.0, 6.3, 6.3, 6.4, 6.4, 6.6, 6.6, 6.7)

n_hombres <- length(hombres)
n_mujeres <- length(mujeres)

# Comprobar normalidad de las muestras.
print(shapiro.test(hombres))
print(shapiro.test(mujeres))

# Calcular y mostrar la diferencia observada entre las medias muestrales.
media_hombres <- mean(hombres)
media_mujeres <- mean(mujeres)
diferencia_obs <- media_hombres - media_mujeres

cat("Media hombres:", round(media_hombres, 3), "\n")
cat("Media mujeres:", round(media_mujeres, 3), "\n")
cat("Diferencia observada:", round(diferencia_obs, 3), "\n")
cat("\n")

# Crear la distribución bootstrap.
B <- 9999
set.seed(432)
distribucion_b <- two.boot(hombres, mujeres, FUN = mean, R = B)

# Examinar la distribución bootstrap.
datos <- data.frame(diferencias = distribucion_b[["t"]])
g_hist <- gghistogram(datos, x = "diferencias", bins = 100,
                      xlab = "Diferencia de medias",
                      ylab = "Frecuencia")
g_qq <- ggqqplot(datos, x = "diferencias")
g <- ggarrange(g_hist, g_qq)
print(g)

media_b <- mean(datos[["diferencias"]])
sd_b <- sd(datos[["diferencias"]])

cat("Media de la distribución bootstrap:", round(media_b, 3), "\n")
cat("Desviación estándar de la distribución bootstrap:", round(sd_b, 3), "\n")

#Contruir y mostrar los intervalos de confianza
alfa <- 0.05
intervalo_bca <- boot.ci(distribucion_b, type = c("bca"), conf = 1 - alfa)

print(intervalo_bca)

#Desplazar la distribucion bootstrap para que se centre en el valor nulo

valor_nulo <- -0.5
desplazamiento <- media_b - valor_nulo
distribucion_nula <- datos[["diferencias"]] - desplazamiento

#El valor de P
#Para H0= B-A = X, Ha = B-A < X
p <- (sum(distribucion_nula < diferencia_obs) + 1) / (B + 1)
cat("Valor de P: ", p, "\n")

```
### Bootstraping para dos muestras pareadas

Es necesario que ambas muestras sean de igual largo

```{r}
library(bootES)

set.seed(432)

# Ingresar datos originales.
prueba_1 <- c(3.5, 2.7, 1.0, 1.8, 1.6, 4.3, 5.8, 6.4, 3.9, 4.3, 3.4, 
              5.3, 5.8, 5.3, 2.0, 1.3, 4.0, 5.3, 1.6, 3.6)

prueba_2 <- c(5.2, 5.1, 5.9, 4.8, 1.4, 2.3, 6.8, 5.3, 3.1, 3.8, 4.6, 
              1.2, 3.9, 2.0, 1.7, 3.3, 6.0, 4.8, 6.9, 1.3)

# Calcular la diferencia entre ambas observaciones.
diferencia <- prueba_2 - prueba_1

# Calcular la media observada de las diferencias.
valor_observado <- mean(diferencia)

# Generar la distribución bootstrap y su intervalo de confianza.
B <- 3999
alfa <- 0.05

distribucion_bES <- bootES(diferencia, R = B, ci.type = "bca", 
                           ci.conf = 1 - alfa, plot = FALSE)

# Desplazar la distribución bootstrap para reflejar la hipótesis nula.
#H0 = X, Ha != X
valor_nulo <- 0.5
desplazamiento <- mean(distribucion_bES[["t"]]) - valor_nulo
distribucion_nula <- distribucion_bES[["t"]] - desplazamiento

# Determinar el valor p.
p <- (sum(abs(distribucion_nula) > abs(valor_observado)) + 1) / (B + 1)

# Mostrar los resultados
cat("Media de las diferencia observada:", round(valor_observado, 3), "\n\n")
cat("Distribución bootstrap e intervalo de confianza:\n")
print(distribucion_bES)
cat("Valor p:", round(p, 3), "\n")

```
## Pruebas de permutaciones

### Prueba de permutaciones para 2 muestras independientes

```{r}
library(ggpubr)

# Crear muestras iniciales.
a <- c(5.4, 4.7, 6.3, 2.9, 5.9, 5.1, 2.1, 6.2, 1.6, 6.7, 3.0, 3.3,
       5.0, 4.1, 3.3, 3.4, 4.2, 1.2, 3.8, 5.8, 4.2)

b <- c(4.0, 4.1, 4.3, 4.3, 4.3, 4.2, 4.3, 4.3, 4.4, 4.1, 4.3, 4.0)

# Establecer semilla y cantidad de repeticiones.
R <- 5999
set.seed(432)

# Función para obtener una permutación.
# Argumentos:
# - i: iterador (para llamadas posteriores).
# - muestra_1, muestra_2: muestras.
# Valor:
# - lista con las muestras resultantes tras la permutación.
obtiene_permutacion <- function(i, muestra_1, muestra_2) {
  n_1 <- length(muestra_1)
  combinada <- c(muestra_1, muestra_2)
  n <- length(combinada)
  permutacion <- sample(combinada, n, replace = FALSE)
  nueva_1 <- permutacion[1:n_1]
  nueva_2 <- permutacion[(n_1+1):n]
  return(list(nueva_1, nueva_2))
}

# Función para calcular la diferencia de un estadístico de interés entre las dos muestras.
# Argumentos:
# - muestras: lista con las muestras.
# - FUN: nombre de la función que calcula el estadístico de interés.
# Valor:
# - diferencia de un estadístico para dos muestras.
calcular_diferencia <- function(muestras, FUN) {
  muestra_1 <- muestras[[1]]
  muestra_2 <- muestras[[2]]
  diferencia <- FUN(muestra_1) - FUN(muestra_2)
  return(diferencia)
}

# Función para calcular el valor p.
# Argumentos:
# - distribucion: distribución nula del estadístico de interés.
# - observado: valor del estadístico de interés para las muestras originales.
# - repeticiones: cantidad de permutaciones a realizar.
# - alternative: tipo de hipótesis alternativa. "two.sided" para hipótesis bilateral,
#   "greater" o "less" para hipótesis unilaterales.

calcular_p <- function(distribucion, valor_observado, repeticiones, alternative){
  if(alternative == "two.sided"){
    numedador <- sum(abs(distribucion) >= abs(valor_observado)) + 1
    denominador <- repeticiones + 1
    valor_p <- numedador / denominador
  }
  else if(alternative == "greater"){
    numedador <- sum(distribucion > valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numedador / denominador
  }
  else {
    numedador <- sum(distribucion < valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numedador / denominador
  }
  
  return (valor_p)
}

# Función para graficar una distribución.
# Argumentos:
# - distribucion: distribución nula del estadístico de interés.
# - ...: otros argumentos a ser entregados a gghistogram y ggqqplot.
graficar_distribucion <- function(distribucion, ...) {
  observaciones <- data.frame(distribucion)
  
  histograma <- gghistogram(observaciones, x = "distribucion",
                            xlab = "Estadístico de interés",
                            ylab = "Frecuencia", bins = 30, ...)
  
  qq <- ggqqplot(observaciones, x = "distribucion", ...)
  
  # Crear una única figura con todos los gráficos de dispersión.
  figura <- ggarrange(histograma, qq, ncol = 2, nrow = 1)
  print(figura)
}

# Función para hacer la prueba de permutaciones.
# Argumentos:
# - muestra_1, muestra_2: vectores numéricos con las muestras a comparar.
# - repeticiones: cantidad de permutaciones a realizar.
# - FUN: función del estadístico E para el que se calcula la diferencia.
# - alternative: tipo de hipótesis alternativa. "two.sided" para 
#   hipótesis bilateral, "greater" o "less" para hipótesis unilaterales.
# - plot: si es TRUE, construye el gráfico de la distribución generada.
# - ...: otros argumentos a ser entregados a graficar_distribucion.
contrastar_hipotesis_permutaciones <- function(muestra_1, muestra_2,
                                               repeticiones, FUN,
                                               alternative, plot, ...) {
  cat("Prueba de permutaciones\n\n")
  cat("Hipótesis alternativa:", alternative, "\n")
  observado <- calcular_diferencia(list(muestra_1, muestra_2), FUN)
  cat("Valor observado:", observado, "\n")
  
  n_1 <- length(muestra_1)
  
  # Generar permutaciones.
  permutaciones <- lapply(1:repeticiones, obtiene_permutacion, muestra_1, muestra_2)
  
  # Generar la distribución.
  distribucion <- sapply(permutaciones, calcular_diferencia, FUN)
  
  # Graficar la distribución.
  if(plot) {
    graficar_distribucion(distribucion, ...)
  }
  
  # Calcular el valor p.
  valor_p <- calcular_p(distribucion, observado, repeticiones, alternative)
  cat("Valor p:", valor_p, "\n")
}

#Pruebas de permutaciones para la media y varianza
contrastar_hipotesis_permutaciones(a, b, repeticiones =  R, FUN = mean, alternative =  "two.sided", plot = TRUE, color = "blue", fill = "blue")


contrastar_hipotesis_permutaciones(a, b, repeticiones =  R, FUN = var, alternative =  "two.sided", plot = FALSE)

```


### Prueba de permutaciones para comparar mas de 2 muestras correlacionadas

```{r}
library(ez)
library(ggpubr)
library(tidyr)

# Crear la matriz de datos.
Algoritmos <- c("Quicksort", "Bubblesort", "Mergesort")
Quicksort <- c(11.2, 22.6, 23.4, 23.3, 21.8, 40.1)
Bubblesort <- c(15.7, 29.3, 30.7, 30.8, 29.8, 50.3)
Mergesort <- c(12.0, 25.7, 25.7, 23.7, 25.5, 44.7)
Instancia <- factor(1:6)
datos_anchos <- data.frame(Instancia, Quicksort, Bubblesort, Mergesort)

datos_largos <- datos_anchos |>
  pivot_longer(all_of(Algoritmos),
               names_to = "Algoritmo",
               values_to = "Tiempo")
datos_largos[["Algoritmo"]] <- factor(datos_largos[["Algoritmo"]],
                                      levels = Algoritmos)

# Verificar la condición de normalidad.
g <- ggqqplot(datos_largos, "Tiempo", facet.by = "Algoritmo",
              color = "Algoritmo")
print(g)

# Establecer nivel de significación.
alfa <- 0.01

# Obtener el valor observado, correspondiente al estadístico F entregado
# por ANOVA para la muestra original.
anova <- ezANOVA(datos_largos, dv = Tiempo, within = Algoritmo,
                 wid = Instancia)
valor_observado <- anova[["ANOVA"]][["F"]]

# Función para obtener una permutación.
# Devuelve una matriz de datos con formato ancho.
obtiene_permutacion <- function(i, df_ancho) {
  df_ancho[, 2:4] <- t(apply(df_ancho[, 2:4], 1, sample))
  return(df_ancho)
}

# Obtiene permutaciones
R <- 2999
set.seed(432)
permutaciones <- lapply(1:R, obtiene_permutacion, datos_anchos)

#Funcion para obtener el estadistico F de una tabla en formato Largo

obtiene_F <- function(df_ancho){
  df_largo <- df_ancho |> pivot_longer(c("Quicksort", "Bubblesort", "Mergesort"),
                                      names_to = "Algoritmo",
                                      values_to = "Tiempo")
  
  df_largo[["Algoritmo"]] <- factor(df_largo[["Algoritmo"]])
  
  anova <- ezANOVA(df_largo, dv = Tiempo, within = Algoritmo,
                   wid = Instancia)
  return(anova[["ANOVA"]][["F"]])
}

#Generar distribucion de estadistico F con permutaciones

distribucion <- sapply(permutaciones, obtiene_F)

#Calcular el valor de P

p<- (sum(distribucion > valor_observado) + 1) / (R + 1)
cat("ANOVA de una via para muestras pareadas con permutaciones:\n")
cat("Valor p omnibus:", p, "\n")

#Analisis Post-hoc

#Funciona para calcular diferencia de medias para 2 columnas de una matriz en formato ancho.

obtiene_media_difs <- function(df_ancho, col1, col2){
  media <- mean(df_ancho[[col1]] - df_ancho[[col2]])
  return(media)
}

# obtiene las medias de las diferencias observadas

dif_obs_Q_B <- obtiene_media_difs(datos_anchos, "Quicksort", "Bubblesort")
dif_obs_Q_M <- obtiene_media_difs(datos_anchos, "Quicksort", "Mergesort")
dif_obs_B_M <- obtiene_media_difs(datos_anchos, "Bubblesort", "Mergesort")

#Obtiene las distribuciones de las medias de las diferencias permutadas
dist_medias_difs_Q_B <- sapply(permutaciones, obtiene_media_difs, "Quicksort", "Bubblesort")
dist_medias_difs_Q_M <- sapply(permutaciones, obtiene_media_difs, "Quicksort", "Mergesort")
dist_medias_difs_B_M <- sapply(permutaciones, obtiene_media_difs, "Bubblesort", "Mergesort")

#Calcular los valores de P

num <- sum(abs(dist_medias_difs_Q_B) >= abs(dif_obs_Q_B)) + 1
den <- R + 1
p_Q_B <- num / den

num <- sum(abs(dist_medias_difs_Q_M) >= abs(dif_obs_Q_M)) + 1
den <- R + 1
p_Q_M <- num / den

num <- sum(abs(dist_medias_difs_B_M) >= abs(dif_obs_B_M)) + 1
den <- R + 1
p_B_M <- num / den

valores_p <- c(p_Q_B, p_Q_M, p_B_M)

#Ajustar y mostrar valores p

valores_p_adj <- p.adjust(valores_p, method = "BH")

cat("\n\n")

cat("Analisis post-hoc (permutaciones) para la diferencia de medias:\n")
cat("Valores p ajustados:\n")

cat(sprintf("Quicksort vs. Bubblesort: %.3f\n", valores_p_adj[1]))
cat(sprintf("Quicksort vs. Mergesort: %.3f\n", valores_p_adj[2]))
cat(sprintf("Bubblesort vs. Mergesort: %.3f\n", valores_p_adj[3]))


cat("\n Diferencias observadas:\n")
cat(sprintf("Quicksort vs. Bubblesort: %.3f\n", dif_obs_Q_B))
cat(sprintf("Quicksort vs. Mergesort: %.3f\n", dif_obs_Q_M))
cat(sprintf("Bubblesort vs. Mergesort: %.3f\n", dif_obs_B_M))



```

# Regresion Lineal

## Correlacion

### COR

Para calcular la correlacion entre 2 variables podemos hacer uso de cor(x,y) con x predictor, y la respuesta
De forma adicional si X es una matriz nos entrega una Matriz de correlacion cor(x)

## Regresion lineal mediante minimos cuadrados

Este necesita cumplir ciertas condiciones las cuales son:

1.-Las variables presentan una distribucion condicional bivariante, por lo que, para cualquier valor fijo de X, los valores de Y se distribuyen normalmente con una varianza constante.

2.-La relacion entre la variable X y las medias de la variable Y es lineal.

3.-Las observaciones de la muestra son independientes entre si. Esto significa que no se pueden usar regresion lineal con series de tiempo.

Para realizar una regresion lineal simple se hace uso de lm(respuesta ~ predictor, data)
para ver el modelo se hace summary de este

```{r}
library(dplyr)
library(ggpubr)

datos <-mtcars|> filter(wt > 2 & wt < 5)

modelo <- lm(hp ~ disp, data = datos)

print(summary(modelo))
```
Concluimos que las variables utilizaras resultan significativas

## Uso del modelo
