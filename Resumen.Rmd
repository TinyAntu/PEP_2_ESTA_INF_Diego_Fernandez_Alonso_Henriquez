---
title: "Codigo util"
output: html_document
date: "2024-12-26"
---

# Alternativas para analisis de datos problematicos

## Alternativa robusta a las medias

Para cuando contamos con valores extremos atipicos podemos utilizar la media Windorizada la caul se puede calcular con winmean  del paquete WRS2:

```{r}
library(WRS2)
#Ignora el 20% de los datos en cada extremo
x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100)
winmean(x, tr = 0.2)
```
## Prueba de Yuen para 2 muestras independientes

Alternativa a T Student para muestras independientes es utilizada cuando las varianzas de ambas muestras son muy diferentes o los tamaños de las muestras son muy dispares. No se recomienda esto si es que el nivel de truncamiento esta cerca de 0.5.

H0: Medias iguales

Ha: Medias diferentes

La funcion es yuenbt del paquete WRS2 (formula es : Variable dependiente ~ Variable independiente):

```{r}
library(WRS2)
library(ggpubr)

#Ejemplo

a <- c(25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0
       ,26.1,26.2,26.3,26.4,26.5,26.6,26.7,26.8,26.9,27.0,
       27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.4,
       28.5,29.0,29.8,30.2,31.8,31.9,33.3,33.7)

b <- c(24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,24.9,25.0,
       25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0,26.1,
       26.2,26.3,27.1,27.2,
       27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.1,28.2,28.3,30.0,30.1,30.2,30.3)

tiempo <- c(a,b)
algoritmo  <- c(rep("A",length(a)),rep("B",length(b)))
datos <- data.frame(tiempo,algoritmo)

#Comprobar normalidad
#Antes del truncamientio
g <- ggqqplot(datos, x = "tiempo", facet.by = "algoritmo",
             palette = c("blue", "red"), color ="algoritmo")

print(g)

#Poda
gamma <- 0.2

n_a <- length(a)
n_b <- length(b)

poda_a <- n_a * gamma
poda_b <- n_b * gamma

a_truncada <- a[poda_a:(n_a - poda_a)]
b_truncada <- b[poda_b:(n_b - poda_b)]

tiempo <- c(a_truncada,b_truncada)
algoritmo <- c(rep("A",length(a_truncada)),rep("B",length(b_truncada)))
datos_truncados <- data.frame(tiempo,algoritmo)

#Despues del truncamientio 
g <- ggqqplot(datos_truncados, x = "tiempo", facet.by = "algoritmo",
              palette = c("blue", "red"), color = "algoritmo")

print(g)

#Prueba de Yuen
yuen(tiempo ~ algoritmo, data = datos_truncados, tr = gamma)


```
Otra opcion es pb2gen que utiliza boostraping para aplicar la prueba de yuen usando otras medidas robustas de tendencia central.

```{r}
library(WRS2)


#Ejemplo

a <- c(25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0
       ,26.1,26.2,26.3,26.4,26.5,26.6,26.7,26.8,26.9,27.0,
       27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.4,
       28.5,29.0,29.8,30.2,31.8,31.9,33.3,33.7)

b <- c(24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,24.9,25.0,
       25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0,26.1,
       26.2,26.3,27.1,27.2,
       27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.1,28.2,28.3,30.0,30.1,30.2,30.3)

tiempo <- c(a,b)
algoritmo  <- c(rep("A",length(a)),rep("B",length(b)))
datos <- data.frame(tiempo,algoritmo)

bootstrap <- 999

set.seed(135)

prueba_media <- pb2gen(tiempo ~ algoritmo, data = datos, est = "mean", nboot = bootstrap)

cat("Resultado al utilizar media como estimador \n")
print(prueba_media)

set.seed(135)

prueba_mediana <- pb2gen(tiempo ~ algoritmo, data = datos, est = "median", nboot = bootstrap)

cat("Resultado al utilizar mediana como estimador \n")
print(prueba_mediana)

```
## Prueba de Yuen para 2 muestras pareadas

```{r}
library(WRS2)


#Ejemplo

a <- c(25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0
       ,26.1,26.2,26.3,26.4,26.5,26.6,26.7,26.8,26.9,27.0,
       27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0,28.4,
       28.5,29.0,29.8,30.2,31.8,31.9,33.3,33.7)

b <- c(24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,24.9,25.0,
       25.1,25.2,25.3,25.4,25.5,25.6,25.7,25.8,25.9,26.0,26.1,
       26.2,26.3,27.1,27.2,27.3,27.4,27.5,27.6,27.7,27.8,27.9,28.0
       ,28.1,28.2,28.3,30.0,30.1,30.2)

#Aplicar prueba para muestras pareadas

gama <- 0.2
yuend(a, b, tr = gamma)

```
## Comparaciones de una via para multiples grupos independientes

El paquete WRS2 ofrece diferentes alternativas a ANOVA de una via para muestras independientes es util para cuando los tamaño de las muestrasn son muy diferentes o no se cumple la homocedasticidad.

Para esto se utiliza t1way que es un procedimiento como el ANOVA pero con medias truncadas y para el analisis PostHoc es con lincon, para posthoc con bootstrap en con mcppb20.

Otra opcion es med1way que realiza un ANOVA iterativo pero este no cuenta con analisis PostHoc

```{r}
library(WRS2)

#Matriz de datos

a <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 26.6, 26.7, 26.7, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7)

b <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.3, 25.4, 25.7, 25.7, 25.7, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)

c <- c(24.5, 24.5, 24.5, 24.5, 24.5, 24.5, 24.6, 24.6, 24.6, 24.6, 24.7, 24.7, 24.7, 24.7, 24.8, 25.0, 25.0, 25.0, 25.2, 25.2, 25.2, 25.5, 25.5, 25.7, 25.9, 26.2, 26.5, 26.5, 26.7, 27.0, 29.2, 29.9, 30.1)

tiempo <- c(a, b, c)
algoritmo <- c(rep("A", length(a)), rep("B", length(b)), rep("C", length(c)))
datos <- data.frame(tiempo, algoritmo)

# Fijar nivel de significación.
alfa <- 0.05

# Comparar los diferentes algoritmos usando medias truncadas.
cat("Comparación entre grupos usando medias truncadas\n\n")
gamma <- 0.2

set.seed(666)

medias_truncadas <- t1way(tiempo ~ algoritmo, data = datos, tr = gamma, alpha = alfa)


print(medias_truncadas)

set.seed(666)
muestras <- 999

cat("Post hoc iterativo\n\n")

post_hoc <- lincon(tiempo ~ algoritmo, data = datos, tr = gamma, alpha = alfa)

print(post_hoc)

cat("Post hoc con bootstrap\n\n")
set.seed(666)
boot <- t1waybt(tiempo ~ algoritmo, data = datos, tr = gamma, nboot = muestras, alpha = alfa)

print(boot)


set.seed(666)
post_hoc_2 <- mcppb20(tiempo ~ algoritmo, data = datos, tr = gamma, nboot = muestras, alpha = alfa)

print(post_hoc_2)

```
## Comparaciones de una via para multiples grupos correlacionados

Es util cuando los datos violan la condicion de esferecidad 

Para esto la funcion es rmanova y para el post hoc es rmmcp. Aparte para incorporar bootstraping tenemos rmanovab y el post hoc seria con pairdepb

```{r}
library(WRS2)
library(tidyverse)

# Construir data frame.
X <- c(32.0, 32.0, 32.0, 32.0, 32.1, 32.1, 32.1, 32.2, 32.3, 32.3, 32.5,
       32.7, 32.7, 32.7, 33.1, 33.4, 33.9, 34.1, 34.2, 34.5, 36.0, 36.6, 
       36.7, 37.2, 38.0)

Y <- c(33.0, 33.0, 33.0, 33.0, 33.3, 33.3, 33.3, 33.3, 33.5, 
       33.6, 33.7, 33.9, 33.9, 34.2, 34.2, 34.3, 34.3, 34.3, 34.4, 34.4, 
       34.5, 34.6, 36.4, 38.9, 40.2)

Z <- c(32.0, 32.2, 32.5, 32.6, 32.7, 32.7, 32.7, 33.0, 33.2, 33.4, 33.6, 
       33.6, 33.9, 34.1, 34.2, 34.4, 34.4, 34.5, 34.6, 34.7, 36.3, 36.6, 
       36.7, 38.9, 39.2)

instancia <- 1:length(X)
datos <- data.frame(instancia, X, Y, Z)

# Llevar data frame a formato largo
datos_largo <- datos %>% pivot_longer( c("X", "Y", "Z"), names_to = "algoritmo", values_to = "tiempo")

# Convertir columna algoritmo en factor
datos_largo[["algoritmo"]] <- factor(datos_largo[["algoritmo"]])

# Fijar nivel de significación.
alfa <- 0.05

# Aplicar alternativa robusta a ANOVA de una vía con muestras correlacionadas
gamma <- 0.2

prueba <- rmanova(y = datos_largo[["tiempo"]], groups = datos_largo[["algoritmo"]], blocks = datos_largo[["instancia"]], tr = gamma)

print(prueba)

post_hoc <- rmmcp(y = datos_largo[["tiempo"]], groups = datos_largo[["algoritmo"]], blocks = datos_largo[["instancia"]], tr = gamma, alpha = alfa)

print(post_hoc)

```


# Remuestreo

Es una buena alternativa para cuando cuando se necesita inferir sobre parametros distintos de la media o proporcion o bien cuando no se cumplen las condicionees necesarias de alguna prueba.
## Bootstraping

### Bootstraping para una muestra

Para esto tenemos boot el cual genera la distribucion de bootstrap y boo.ci que calcula los intervalos de confianza. Otra opcion que no requiere la implementacion de funcion de calculo de medias es bootES.

```{r}
library(boot)
library(bootES)

#Muestra inicial para el calculo de la media e histograma

muestra <- c(79,75,84,75,94,82,76,90,79,80)
datos <- data.frame(muestra)

#Cantidad de remuestreos
B <- 2000
alfa <- 0.05

# Funcion para calcular el estadistico: media de la muestra
media <- function(valores, i){
  mean(valores[i])
}

#Contruir la distribuccion con boot
set.seed(432)
distribucion_b <- boot(muestra, statistic = media, R = B)

#Grafico de la distribucion de boostrap
cat("Distribución de bootstrap con Boot\n")
print(distribucion_b)
plot(distribucion_b)

#Intervalo de confianza

ics <- boot.ci(distribucion_b, type = c("norm", "perc", "bca"), conf = 1 - alfa)

cat("Intervalos de confianza con Boot.ci\n")
print(ics)

#Contruir la distribuccion con bootES
set.seed(432)
distribucion_b_es <- bootES(muestra,R = B, ci.type="bca", ci.conf = 1-alfa, plot = TRUE)

#Bootstrap con BootES
cat("Distribución de bootstrap con BootES\n")
print(distribucion_b_es)

```
Pero para concluir sobre esta hay que desplazarla para que sea representativa de la hipotesis nula

```{r}
library(boot)
library(bootES)

#Muestra inicial para el calculo de la media e histograma

muestra <- c(79,75,84,75,94,82,76,90,79,80)
valor_observado <- mean(muestra)
datos <- data.frame(muestra)

#Cantidad de remuestreos
B <- 2000
alfa <- 0.05

# Funcion para calcular el estadistico: media de la muestra
media <- function(valores, i){
  mean(valores[i])
}

#Contruir la distribuccion con boot
set.seed(432)
distribucion_b <- boot(muestra, statistic = media, R = B)

#Desplazar la distribucion bootstrap para que se centre en el valor nulo
# RECORDAR QUE ESTO ES PARA H0 = X, Ha > X
valor_nulo <- 75
desplazamiento <- mean(distribucion_b[["t"]]) - valor_nulo
distribucion_nula <- distribucion_b[["t"]] - desplazamiento

#El valor de P

p <- (sum(distribucion_nula > valor_observado)+ 1) / (B+1)
cat("Valor de P: ", p, "\n")

```
Otra opcion es ver si el valor nulo esta dentro del intervalo de confianza ya que si no lo esta sabemos que la H0 no se cumple

### Bootstraping para dos muestras independientes

Se hace uso del paquete simpleboot con la funcion two.boot

```{r}
library(boot)
library(ggpubr)
library(simpleboot)

# Ingresar datos originales
hombres <- c(1.3, 1.5, 1.6, 1.7, 1.7, 1.9, 2.3, 2.4, 2.6, 2.6, 2.7,
             2.8, 3.2, 3.7, 4.1, 4.4, 4.5, 4.8, 5.2, 5.2, 5.3, 5.5,
             5.5, 5.6, 5.6, 5.7, 5.7)

mujeres <- c(3.5, 3.6, 3.8, 4.3, 4.5, 4.5, 4.9, 5.1, 5.3, 5.3, 5.5,
             5.8, 6.0, 6.3, 6.3, 6.4, 6.4, 6.6, 6.6, 6.7)

n_hombres <- length(hombres)
n_mujeres <- length(mujeres)

# Comprobar normalidad de las muestras.
print(shapiro.test(hombres))
print(shapiro.test(mujeres))

# Calcular y mostrar la diferencia observada entre las medias muestrales.
media_hombres <- mean(hombres)
media_mujeres <- mean(mujeres)
diferencia_obs <- media_hombres - media_mujeres

cat("Media hombres:", round(media_hombres, 3), "\n")
cat("Media mujeres:", round(media_mujeres, 3), "\n")
cat("Diferencia observada:", round(diferencia_obs, 3), "\n")
cat("\n")

# Crear la distribución bootstrap.
B <- 9999
set.seed(432)
distribucion_b <- two.boot(hombres, mujeres, FUN = mean, R = B)

# Examinar la distribución bootstrap.
datos <- data.frame(diferencias = distribucion_b[["t"]])
g_hist <- gghistogram(datos, x = "diferencias", bins = 100,
                      xlab = "Diferencia de medias",
                      ylab = "Frecuencia")
g_qq <- ggqqplot(datos, x = "diferencias")
g <- ggarrange(g_hist, g_qq)
print(g)

media_b <- mean(datos[["diferencias"]])
sd_b <- sd(datos[["diferencias"]])

cat("Media de la distribución bootstrap:", round(media_b, 3), "\n")
cat("Desviación estándar de la distribución bootstrap:", round(sd_b, 3), "\n")

#Contruir y mostrar los intervalos de confianza
alfa <- 0.05
intervalo_bca <- boot.ci(distribucion_b, type = c("bca"), conf = 1 - alfa)

print(intervalo_bca)

#Desplazar la distribucion bootstrap para que se centre en el valor nulo

valor_nulo <- -0.5
desplazamiento <- media_b - valor_nulo
distribucion_nula <- datos[["diferencias"]] - desplazamiento

#El valor de P
#Para H0= B-A = X, Ha = B-A < X
p <- (sum(distribucion_nula < diferencia_obs) + 1) / (B + 1)
cat("Valor de P: ", p, "\n")

```
### Bootstraping para dos muestras pareadas

Es necesario que ambas muestras sean de igual largo

```{r}
library(bootES)

set.seed(432)

# Ingresar datos originales.
prueba_1 <- c(3.5, 2.7, 1.0, 1.8, 1.6, 4.3, 5.8, 6.4, 3.9, 4.3, 3.4, 
              5.3, 5.8, 5.3, 2.0, 1.3, 4.0, 5.3, 1.6, 3.6)

prueba_2 <- c(5.2, 5.1, 5.9, 4.8, 1.4, 2.3, 6.8, 5.3, 3.1, 3.8, 4.6, 
              1.2, 3.9, 2.0, 1.7, 3.3, 6.0, 4.8, 6.9, 1.3)

# Calcular la diferencia entre ambas observaciones.
diferencia <- prueba_2 - prueba_1

# Calcular la media observada de las diferencias.
valor_observado <- mean(diferencia)

# Generar la distribución bootstrap y su intervalo de confianza.
B <- 3999
alfa <- 0.05

distribucion_bES <- bootES(diferencia, R = B, ci.type = "bca", 
                           ci.conf = 1 - alfa, plot = FALSE)

# Desplazar la distribución bootstrap para reflejar la hipótesis nula.
#H0 = X, Ha != X
valor_nulo <- 0.5
desplazamiento <- mean(distribucion_bES[["t"]]) - valor_nulo
distribucion_nula <- distribucion_bES[["t"]] - desplazamiento

# Determinar el valor p.
p <- (sum(abs(distribucion_nula) > abs(valor_observado)) + 1) / (B + 1)

# Mostrar los resultados
cat("Media de las diferencia observada:", round(valor_observado, 3), "\n\n")
cat("Distribución bootstrap e intervalo de confianza:\n")
print(distribucion_bES)
cat("Valor p:", round(p, 3), "\n")

```
## Pruebas de permutaciones

### Prueba de permutaciones para 2 muestras independientes

```{r}
library(ggpubr)

# Crear muestras iniciales.
a <- c(5.4, 4.7, 6.3, 2.9, 5.9, 5.1, 2.1, 6.2, 1.6, 6.7, 3.0, 3.3,
       5.0, 4.1, 3.3, 3.4, 4.2, 1.2, 3.8, 5.8, 4.2)

b <- c(4.0, 4.1, 4.3, 4.3, 4.3, 4.2, 4.3, 4.3, 4.4, 4.1, 4.3, 4.0)

# Establecer semilla y cantidad de repeticiones.
R <- 5999
set.seed(432)

# Función para obtener una permutación.
# Argumentos:
# - i: iterador (para llamadas posteriores).
# - muestra_1, muestra_2: muestras.
# Valor:
# - lista con las muestras resultantes tras la permutación.
obtiene_permutacion <- function(i, muestra_1, muestra_2) {
  n_1 <- length(muestra_1)
  combinada <- c(muestra_1, muestra_2)
  n <- length(combinada)
  permutacion <- sample(combinada, n, replace = FALSE)
  nueva_1 <- permutacion[1:n_1]
  nueva_2 <- permutacion[(n_1+1):n]
  return(list(nueva_1, nueva_2))
}

# Función para calcular la diferencia de un estadístico de interés entre las dos muestras.
# Argumentos:
# - muestras: lista con las muestras.
# - FUN: nombre de la función que calcula el estadístico de interés.
# Valor:
# - diferencia de un estadístico para dos muestras.
calcular_diferencia <- function(muestras, FUN) {
  muestra_1 <- muestras[[1]]
  muestra_2 <- muestras[[2]]
  diferencia <- FUN(muestra_1) - FUN(muestra_2)
  return(diferencia)
}

# Función para calcular el valor p.
# Argumentos:
# - distribucion: distribución nula del estadístico de interés.
# - observado: valor del estadístico de interés para las muestras originales.
# - repeticiones: cantidad de permutaciones a realizar.
# - alternative: tipo de hipótesis alternativa. "two.sided" para hipótesis bilateral,
#   "greater" o "less" para hipótesis unilaterales.

calcular_p <- function(distribucion, valor_observado, repeticiones, alternative){
  if(alternative == "two.sided"){
    numedador <- sum(abs(distribucion) >= abs(valor_observado)) + 1
    denominador <- repeticiones + 1
    valor_p <- numedador / denominador
  }
  else if(alternative == "greater"){
    numedador <- sum(distribucion > valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numedador / denominador
  }
  else {
    numedador <- sum(distribucion < valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numedador / denominador
  }
  
  return (valor_p)
}

# Función para graficar una distribución.
# Argumentos:
# - distribucion: distribución nula del estadístico de interés.
# - ...: otros argumentos a ser entregados a gghistogram y ggqqplot.
graficar_distribucion <- function(distribucion, ...) {
  observaciones <- data.frame(distribucion)
  
  histograma <- gghistogram(observaciones, x = "distribucion",
                            xlab = "Estadístico de interés",
                            ylab = "Frecuencia", bins = 30, ...)
  
  qq <- ggqqplot(observaciones, x = "distribucion", ...)
  
  # Crear una única figura con todos los gráficos de dispersión.
  figura <- ggarrange(histograma, qq, ncol = 2, nrow = 1)
  print(figura)
}

# Función para hacer la prueba de permutaciones.
# Argumentos:
# - muestra_1, muestra_2: vectores numéricos con las muestras a comparar.
# - repeticiones: cantidad de permutaciones a realizar.
# - FUN: función del estadístico E para el que se calcula la diferencia.
# - alternative: tipo de hipótesis alternativa. "two.sided" para 
#   hipótesis bilateral, "greater" o "less" para hipótesis unilaterales.
# - plot: si es TRUE, construye el gráfico de la distribución generada.
# - ...: otros argumentos a ser entregados a graficar_distribucion.
contrastar_hipotesis_permutaciones <- function(muestra_1, muestra_2,
                                               repeticiones, FUN,
                                               alternative, plot, ...) {
  cat("Prueba de permutaciones\n\n")
  cat("Hipótesis alternativa:", alternative, "\n")
  observado <- calcular_diferencia(list(muestra_1, muestra_2), FUN)
  cat("Valor observado:", observado, "\n")
  
  n_1 <- length(muestra_1)
  
  # Generar permutaciones.
  permutaciones <- lapply(1:repeticiones, obtiene_permutacion, muestra_1, muestra_2)
  
  # Generar la distribución.
  distribucion <- sapply(permutaciones, calcular_diferencia, FUN)
  
  # Graficar la distribución.
  if(plot) {
    graficar_distribucion(distribucion, ...)
  }
  
  # Calcular el valor p.
  valor_p <- calcular_p(distribucion, observado, repeticiones, alternative)
  cat("Valor p:", valor_p, "\n")
}

#Pruebas de permutaciones para la media y varianza
contrastar_hipotesis_permutaciones(a, b, repeticiones =  R, FUN = mean, alternative =  "two.sided", plot = TRUE, color = "blue", fill = "blue")


contrastar_hipotesis_permutaciones(a, b, repeticiones =  R, FUN = var, alternative =  "two.sided", plot = FALSE)

```


### Prueba de permutaciones para comparar mas de 2 muestras correlacionadas

```{r}
library(ez)
library(ggpubr)
library(tidyr)

# Crear la matriz de datos.
Algoritmos <- c("Quicksort", "Bubblesort", "Mergesort")
Quicksort <- c(11.2, 22.6, 23.4, 23.3, 21.8, 40.1)
Bubblesort <- c(15.7, 29.3, 30.7, 30.8, 29.8, 50.3)
Mergesort <- c(12.0, 25.7, 25.7, 23.7, 25.5, 44.7)
Instancia <- factor(1:6)
datos_anchos <- data.frame(Instancia, Quicksort, Bubblesort, Mergesort)

datos_largos <- datos_anchos |>
  pivot_longer(all_of(Algoritmos),
               names_to = "Algoritmo",
               values_to = "Tiempo")
datos_largos[["Algoritmo"]] <- factor(datos_largos[["Algoritmo"]],
                                      levels = Algoritmos)

# Verificar la condición de normalidad.
g <- ggqqplot(datos_largos, "Tiempo", facet.by = "Algoritmo",
              color = "Algoritmo")
print(g)

# Establecer nivel de significación.
alfa <- 0.01

# Obtener el valor observado, correspondiente al estadístico F entregado
# por ANOVA para la muestra original.
anova <- ezANOVA(datos_largos, dv = Tiempo, within = Algoritmo,
                 wid = Instancia)
valor_observado <- anova[["ANOVA"]][["F"]]

# Función para obtener una permutación.
# Devuelve una matriz de datos con formato ancho.
obtiene_permutacion <- function(i, df_ancho) {
  df_ancho[, 2:4] <- t(apply(df_ancho[, 2:4], 1, sample))
  return(df_ancho)
}

# Obtiene permutaciones
R <- 2999
set.seed(432)
permutaciones <- lapply(1:R, obtiene_permutacion, datos_anchos)

#Funcion para obtener el estadistico F de una tabla en formato Largo

obtiene_F <- function(df_ancho){
  df_largo <- df_ancho |> pivot_longer(c("Quicksort", "Bubblesort", "Mergesort"),
                                      names_to = "Algoritmo",
                                      values_to = "Tiempo")
  
  df_largo[["Algoritmo"]] <- factor(df_largo[["Algoritmo"]])
  
  anova <- ezANOVA(df_largo, dv = Tiempo, within = Algoritmo,
                   wid = Instancia)
  return(anova[["ANOVA"]][["F"]])
}

#Generar distribucion de estadistico F con permutaciones

distribucion <- sapply(permutaciones, obtiene_F)

#Calcular el valor de P

p<- (sum(distribucion > valor_observado) + 1) / (R + 1)
cat("ANOVA de una via para muestras pareadas con permutaciones:\n")
cat("Valor p omnibus:", p, "\n")

#Analisis Post-hoc

#Funciona para calcular diferencia de medias para 2 columnas de una matriz en formato ancho.

obtiene_media_difs <- function(df_ancho, col1, col2){
  media <- mean(df_ancho[[col1]] - df_ancho[[col2]])
  return(media)
}

# obtiene las medias de las diferencias observadas

dif_obs_Q_B <- obtiene_media_difs(datos_anchos, "Quicksort", "Bubblesort")
dif_obs_Q_M <- obtiene_media_difs(datos_anchos, "Quicksort", "Mergesort")
dif_obs_B_M <- obtiene_media_difs(datos_anchos, "Bubblesort", "Mergesort")

#Obtiene las distribuciones de las medias de las diferencias permutadas
dist_medias_difs_Q_B <- sapply(permutaciones, obtiene_media_difs, "Quicksort", "Bubblesort")
dist_medias_difs_Q_M <- sapply(permutaciones, obtiene_media_difs, "Quicksort", "Mergesort")
dist_medias_difs_B_M <- sapply(permutaciones, obtiene_media_difs, "Bubblesort", "Mergesort")

#Calcular los valores de P

num <- sum(abs(dist_medias_difs_Q_B) >= abs(dif_obs_Q_B)) + 1
den <- R + 1
p_Q_B <- num / den

num <- sum(abs(dist_medias_difs_Q_M) >= abs(dif_obs_Q_M)) + 1
den <- R + 1
p_Q_M <- num / den

num <- sum(abs(dist_medias_difs_B_M) >= abs(dif_obs_B_M)) + 1
den <- R + 1
p_B_M <- num / den

valores_p <- c(p_Q_B, p_Q_M, p_B_M)

#Ajustar y mostrar valores p

valores_p_adj <- p.adjust(valores_p, method = "BH")

cat("\n\n")

cat("Analisis post-hoc (permutaciones) para la diferencia de medias:\n")
cat("Valores p ajustados:\n")

cat(sprintf("Quicksort vs. Bubblesort: %.3f\n", valores_p_adj[1]))
cat(sprintf("Quicksort vs. Mergesort: %.3f\n", valores_p_adj[2]))
cat(sprintf("Bubblesort vs. Mergesort: %.3f\n", valores_p_adj[3]))


cat("\n Diferencias observadas:\n")
cat(sprintf("Quicksort vs. Bubblesort: %.3f\n", dif_obs_Q_B))
cat(sprintf("Quicksort vs. Mergesort: %.3f\n", dif_obs_Q_M))
cat(sprintf("Bubblesort vs. Mergesort: %.3f\n", dif_obs_B_M))



```

# Regresion Lineal

## Correlacion

### COR

Para calcular la correlacion entre 2 variables podemos hacer uso de cor(x,y) con x predictor, y la respuesta
De forma adicional si X es una matriz nos entrega una Matriz de correlacion cor(x)

## Regresion lineal mediante minimos cuadrados

Este necesita cumplir ciertas condiciones las cuales son:

1.-Las variables presentan una distribucion condicional bivariante, por lo que, para cualquier valor fijo de X, los valores de Y se distribuyen normalmente con una varianza constante.

2.-La relacion entre la variable X y las medias de la variable Y es lineal.

3.-Las observaciones de la muestra son independientes entre si. Esto significa que no se pueden usar regresion lineal con series de tiempo.

Para realizar una regresion lineal simple se hace uso de lm(respuesta ~ predictor, data)
para ver el modelo se hace summary de este

```{r}
library(dplyr)
library(ggpubr)

datos <-mtcars|> filter(wt > 2 & wt < 5)

modelo <- lm(hp ~ disp, data = datos)

print(summary(modelo))

#Usar modelo para predecir
#potencia_est <- predict(modelo, data.frame(disp))

#Graficar valores predichos
#nuevo <- data.frame(disp, hp=  potencia_est)
#g2 <- ggscatter(nuevo, x ="disp", y = "hp",
                #color = "purple", fill ="purple",
                #ylab = "Potencia [hp]")

#g2 <- g2+ xlab(bquote("Volumen util de los cilindros" ~ group("[","in"^3]")))

```
Concluimos que las variables utilizaras resultan significativas

## Uso del modelo

El parametro mas importante es el estimado ya que nos dice que por cada pulgada cubica del volumen util de los cilindros en vehiculos que pesan entre 2 y 5 mil libras, la potencia del motor aumenta en promedio 0,50

El cual es estimado del coeficiente, La intercepcion es el valor que se obtendria si el predictor fuese 0.

Hay que tener cuidado con extrapolar los estudios ya que son casos segregados que solo tiene fuerza dentro de su propio contexto.

En R Predict nos permite usar un modelo para predecir valores predict(modelo, valores a estimar) 

## Regresion lineal con un predictor categorico

Para esto haremos uso de variables categorias de 2 niveles (dicotomica) y gracias a las funciones de R no tenemos que realizar modificaciones manuales

```{r}
library(ggpubr)

datos <- mtcars |>
  filter(wt > 2 & wt < 5)

#Verificar correlacion
print(cor(datos[,c("hp","am","vs")]))

#Ajustar modelo
modelo_vs <- lm(hp~ vs, data =datos)
print(summary(modelo_vs))
```
## Confiabilidad del modelo

Estas comprobaciones se realizan antes de utilizar el modelo, si alguna condicion no se cumple el modelo resulta no confiable

### Bondad de ajuste

Con un mayor R^2 se consigue un modelo con mayor reduccion de la varianza por lo cual mientras mas cerca este del valor de 1 resulta que tiene un mejor ajuste

### Distribucion e independecia

Para determinar esto hace falta realizar un analisis a los graficos de los residuos donde estos deben cumplir con que 

1.Se dsitribuyen aleatoriamente en torno a la linea de valor 0

2.Forman una "banda horizontal" en torno a la linea de valor 0

3.No hay residuos que se alejen del patron que forman los demas

4.No forman un patron reconocible

del paquete car tenemos residualPlots(modelo, type ="pearson) que despliega los graficos de necesarios 
aparte del analisis humano tenemos que hacer uso de durbinWatsonTest(modelo) para detectar auto correlacion entre los residuos

Otra funcion de diagnostico util es marginalModelPlots(modelo, sd = FALSE)

Con ncvTest(modelo) para verificar si la variabilidad aumenta a medida que el predictor crece

cabe recalclar que si no se Cumple alguna condicion queda la opcion de buscar otras formas de modificarlo y arreglarlo con tecnicas anteriores o bien utilizar otro predictor que no presente estas problematicas

```{r}
library(car)
library(dplyr)
library(ggpubr)

datos <- mtcars |>
  filter(wt > 2 & wt < 5)

#Modelo de RLS

modelo <- lm(hp ~ disp, data = datos)

#Graficos de residuo y pruebas curvatura

cat("Pruebas de Curvatura:\n")
residualPlots(modelo, type = "rstandard",
              id = list(method = "r",n = 3, cex = 0,7, location = "lr"),
              col ="steelblue", pch  = 20, col.quad ="red")

#Verificar independencia de los residuos
set.seed(19)
db <- durbinWatsonTest(modelo)
cat("Prueba de independencia:\n")
print(db)

#Graficos marginales
marginalModelPlots(modelo, sd= TRUE,
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue", "red"))

# Prueba de la varianza del error no constante
cat("\n Prueba de homocedasticidad:\n")
print(ncvTest(modelo))

#Desplegar graficos de influencia
casos_influyentes <- influencePlot(modelo, id = list(cex = 0.7))
cat("Casos influyentes:\n")
print(casos_influyentes)


```


### Influencia de los valores atipicos

## Calidad predictiva de un modelo RLS

se utilia el MSE

## Generelizacion

Se suele utilizar la validacion cruzada donde los datos iniciales se divide en un conjunto de entrenamiento y otro de prueba donde al terminar de hacer el analisis con los de entrenamiento vemos como se comporta con el conjunto de prueba

```{r}

datos <- mtcars |>
  filter(wt > 2 & wt < 5)
n <- nrow(datos)

#Creacion de los conjuntos
set.seed(101)
n_entrenamiento <- floor(0.8*n)
i_entrenamiento <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)
entrenamiento <- datos[i_entrenamiento, ]
pruebas <- datos[-i_entrenamiento, ]

#Ajustar y mostrar el modelo
modelo <- lm(hp ~ disp, data = entrenamiento)
print(summary(modelo))

#Calcular error cuadrado promedio para el conjunto de entrenamiento

rmse_entrenamiento <- sqrt(mean(resid(modelo)**2))
cat ("MSE para el conjunto de entrenamiento:", rmse_entrenamiento, "\n")

#Hacer las predicciones para el conjunto de prueba

predicciones <- predict(modelo, newdata = pruebas)

#calcular error cuadratico promedio para la prueba
error <- pruebas[["hp"]] - predicciones
rmse_pruebas <- sqrt(mean(error**2))
cat("MSE para el conjunto de pruebas:", rmse_pruebas, "\n")

```
Al ser valores parecidos, suguiere que el modelo generaliza bien otros datos

### Validacion cruzada de K pliegues

para esto se utiliza train(formula, method = "lm", trControl = trainControl(method = "cv", number = K)) del paquete caret 

```{r}
library(caret)
library(dplyr)

datos <- mtcars |>
  filter(wt > 2 & wt < 5)
n <- nrow(datos)

# Ajustar y mostrar el modelo con validacion cruzada de 5 pliegues

set.seed(111)
entrenamiento <- train(hp ~ disp, data = datos, method = "lm",
                       trControl = trainControl(method = "cv", number = 5))
modelo <- entrenamiento[["finalModel"]]
print(summary(modelo))

#Mostrar los resultados de cada pligue
cat("Errores en cada pliegue:\n")
print(entrenamiento[["resample"]])

#Mostrar el resultado estimado para el modelo

cat("Error estimado para el modelo:\n")
print(entrenamiento[["results"]])

```

Al haber gran variaciones en los pliegues implica que hay cierto valores que su presencia o no, provocan grandes cambios en los coeficientes de la recta de regresion

### Validacion cruzada dejando uno fuera

Cuando la muestra disponible es pequeña resulta util utilizar este metodo

```{r}
library(caret)
library(dplyr)

datos <- mtcars |>
  filter(wt > 2 & wt < 5)
n <- nrow(datos)

# Ajustar y mostrar el modelo con validacion cruzada de 5 pliegues

set.seed(111)
entrenamiento <- train(hp ~ disp, data = datos, method = "lm",
                       trControl = trainControl(method = "LOOCV"))
modelo <- entrenamiento[["finalModel"]]
print(summary(modelo))

#Mostrar los resultados de cada pligue
cat("Predicciones en cada pliegue:\n")
print(entrenamiento[["pred"]])

#Mostrar el resultado estimado para el modelo

cat("Error estimado para el modelo:\n")
print(entrenamiento[["results"]])

```

# Regresion lineal multiple

## Modelo de RLM

```{r}
library(dplyr)
library(scatterplot3d)

datos <- mtcars |>
  filter(wt > 2 & wt < 5)

modelo <- lm(hp ~ disp + wt, data = datos)

print(summary(modelo))

```
## Predictores categoricos no dicotomicos

Para esto podemos hace uso de de dummy(x) que retorna la matriz donde se permite transformar los indicadores en variables categoricas


```{r}
library(dummy)

# Crear una matriz de datos.
persona <- 1:9
sexo <- c("F", "F", "M", "M", "M", "F", "F", "M", "F")
tipo <- c("B", "D", "A", "B", "A", "C", "D", "D", "D")
valor <- c(1.68, 2.79, 1.92, 2.26, 2.1, 2.63, 2.19, 3.62, 2.76)
datos <- data.frame(persona, sexo, tipo, valor)

# Crear variables artificiales.
datos.dummy <- dummy(datos)
datos.dummy[["sexo_F"]] <- NULL
datos.dummy[["tipo_A"]] <- NULL
datos.dummy[["valor"]] <- datos[["valor"]]

# Crear y mostrar el modelo de RLM usando variables indicadoras
modelo <- lm(valor ~ sexo_M + tipo_B + tipo_C + tipo_D, datos.dummy)
print(modelo)

# Crear y mostrar el modelo de RLM dejando el trabajo a lm().
modelo_directo <- lm(valor ~ sexo + tipo, datos)
print(modelo_directo)

```
## Ajuste de un modelo de RLM

Para este caso R^2 no resulta del todo confiable ya que este valor siempre aumenta con la cantidad de los predictores sin importa la calidad de estos, por lo que puede llevar a una falsa sensacion de mejora del modelo.

Por lo cual se utiliza AIC(modelo) y BIC(modelo) donde simplemente seria calcularlo para diferentes predictores y ver cual combinacion o predictor reduce mas estos.

Pero estos tampoco resultan la mejor opcion por lo cual se utiliza pf para asi comparar de manera directa el modelo de RLS y RLM  pero la forma mas sencilla resulta con anova

```{r}
library(dplyr)

# Cargar y filtrar los datos.
datos <- mtcars |> filter(wt > 2 & wt < 5)

# Ajustar el modelo nulo, sin predictores,
# solo intercepto.
modelo_0 <- lm(hp ~ 1, data = datos)

# Ajustar un modelo con volumen de los cilindros
# como predictor.
modelo_1 <- lm(hp ~ disp, data = datos)

# Ajustar un modelo añadiendo el peso como predictor.
modelo_2 <- lm(hp ~ disp + wt, data = datos)

# Mostrar AIC y BIC de los modelos
cat("Modelo 0: AIC =", AIC(modelo_0), "\n")
cat("Modelo 1: AIC =", AIC(modelo_1), "\n")
cat("Modelo 2: AIC =", AIC(modelo_2), "\n")
cat("\n")
cat("Modelo 0: BIC =", BIC(modelo_0), "\n")
cat("Modelo 1: BIC =", BIC(modelo_1), "\n")
cat("Modelo 2: BIC =", BIC(modelo_2), "\n")

# Comparar los modelos.
comparacion <- anova(modelo_0, modelo_1, modelo_2)

cat("\n")
cat("Prueba de bondad de ajuste:\n")
print(comparacion)



```

## Seleccion de predictores

No

## Regresion paso a paso

### Seleccion hacia adelante

A apartir del modelo nulo se decide la variable mas prometedora para agregarla al modelo. Para hacer este proceso se utiliza update() y add1(modelo, scope, test)

```{r}
library(dplyr)

#Cargar datos
datos <- mtcars |> 
  filter(wt > 2 & wt < 5) |> 
  mutate_at(c("cyl", "vs", "am", "gear", "carb"), as.factor)


#Ajustar el modelo nulo
nulo <- lm(hp ~ 1, data = datos)
completo <- lm(hp ~ ., data = datos)

cat("Seleccion hacia adelante:\n")
cat("-------------------------\n")

#Evaluar variables para incorporar
paso <- add1(nulo, scope = completo , test = "F")
print(paso, digits = 3, signif.legend =FALSE)

#Agregar la variable con mayor reduccion  de la varianza no explicada (menor AIC)
modelo <- update(nulo, . ~ . + cyl)

#Evaluar variables para incorporar
paso1 <- add1(modelo, scope = completo , test = "F")
cat("'n")
print(paso1, digits = 3, signif.legend =FALSE)

#Agregar la variable con mayor reduccion  de la varianza no explicada (menor AIC)
modelo <- update(modelo, . ~ . + carb)

# Mostrar coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])
```


### Seleccion hacia atras

Desde el modelo completo se con todos los predictores posibles y se elimina 1 a 1Para hacer este proceso se utiliza update() y drop1(modelo, scope, test)

```{r}
library(dplyr)

#Cargar datos
datos <- mtcars |> 
  filter(wt > 2 & wt < 5) |> 
  mutate_at(c("cyl", "vs", "am", "gear", "carb"), as.factor)


#Ajustar el modelo nulo
nulo <- lm(hp ~ 1, data = datos)
completo <- lm(hp ~ ., data = datos)

cat("Eliminacion hacia atras:\n")
cat("-------------------------\n")

#Evaluar variables para incorporar
paso <- drop1(completo, test = "F")
print(paso, digits = 3, signif.legend =FALSE)

#Agregar la variable con mayor reduccion  de la varianza no explicada (menor Estadistico F)
modelo <- update(completo, . ~ . - wt)

#Evaluar variables para incorporar
paso <- drop1(modelo , test = "F")
cat("'n")
print(paso, digits = 3, signif.legend =FALSE)

#Agregar la variable con mayor reduccion  de la varianza no explicada (menor AIC)
modelo <- update(modelo, . ~ . - drat)

# Mostrar coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])
```

### Regresion escalonada STEP

Combinacion de los otros 2 donde hacemos uso de step(modelo, scope, direction, trace) Para la seleccion de predictores se utiliza el que posea menor AIC para el siguiente codigo es BIC aunque diga AIC

```{r}
library(dplyr)

# Cargar y filtrar los datos.
datos <- mtcars |> filter(wt > 2 & wt < 5) |> 
  mutate_at(c("cyl", "vs", "am", "gear", "carb"), as.factor)

# Ajustar el modelo nulo y el modelo completo.
nulo <- lm(hp ~ 1, data = datos)
completo <- lm(hp ~ ., data = datos)

# Realiza regresión escalonada usando el menor BIC
# como criterio (aunque se reporta como AIC), bajando
# (temporalmente) el número de cifras significativas
# y el ancho máximo de la pantalla al imprimir.
opt <- options(digits = 2, width = 54)
modelo <- step(nulo, scope = list(lower = nulo, upper = completo),
               direction = "both", k = log(nrow(datos)),
               test = "F", trace = 1)
options(digits = opt[[1]], width = opt[[2]])

# Mostrar los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])

```

### Busqueda exhaustiva Regsubsets

El paquete leaps nos permite hacer una busqueda exhaustiva de los modelos posibles con regsubsets(formula, data, nbest = cantidad de modelos a reportar, nvmax = cantidad max de predictores, method = "exhaustive")

```{r}
library(dplyr)
library(leaps)

# Cargar y filtrar los datos.
datos <- mtcars |> filter(wt > 2 & wt < 5) |> 
  mutate_at(c("cyl", "vs", "am", "gear", "carb"), as.factor)

# Evaluar todas las combinaciones
combinaciones <- regsubsets(hp ~ ., data = datos, 
                            nbest = 1, nvmax = 16, 
                            method = "exhaustive")

# Graficar los resultados
plot(combinaciones)

# Extraer los mejores subconjuntos
comb_summary <- summary(combinaciones)
i_min_bic <- which.min(comb_summary[["bic"]])
i_max_r2a <- which.max(comb_summary[["adjr2"]])

mejor_comb_bic <- comb_summary[["which"]][i_min_bic, ]
mejor_comb_r2a <- comb_summary[["which"]][i_max_r2a, ]

# Extraer las variables seleccionadas
comb_mejor_bic <- names(mejor_comb_bic[mejor_comb_bic == TRUE])
comb_mejor_r2a <- names(mejor_comb_r2a[mejor_comb_r2a == TRUE])

# Eliminar variables indicadoras
nombres_mejor_bic <- unique(gsub("(.*)\\d$", "\\1", comb_mejor_bic))
nombres_mejor_r2a <- unique(gsub("(.*)\\d$", "\\1", comb_mejor_r2a))

# Obtener las fórmulas
pred_mejor_bic <- paste(nombres_mejor_bic[-1], collapse = " + ")
pred_mejor_r2a <- paste(nombres_mejor_r2a[-1], collapse = " + ")

fmla_mejor_bic <- as.formula(paste("hp", pred_mejor_bic, sep = " ~ "))
fmla_mejor_r2a <- as.formula(paste("hp", pred_mejor_r2a, sep = " ~ "))

# Construir y mostrar los mejores modelos
modelo_mejor_bic <- lm(fmla_mejor_bic, data = datos)
modelo_mejor_r2a <- lm(fmla_mejor_r2a, data = datos)

cat("Modelo que minimiza el BIC:\n")
cat("---------------------------------------------------------\n")
print(modelo_mejor_bic)
cat("\n")
print(nombres_mejor_bic)
cat("\n")
cat("Modelo que maximiza el coeficiente de determinación ajustado:\n")
cat("---------------------------------------------------------\n")
print(modelo_mejor_r2a)
cat("\n")
print(nombres_mejor_r2a)

```

## Confiabilidad de un modelo de RLM

Para que sea confiable deben cumplirse los siguientes puntos

1.La variable de respuesta debe ser cuantitavia y continua sin restricciones para su variabilidad

2.Los predictores deben ser cuantitativos o dicotomicos











## Evaluacion de un clasificador Rlog

Verdaderos positivos (VP): Cantidad de instacias correctamente clasificadas como clase positiva
Falsos positivos (FP): Cantidad de instancias erronaeamente clasificadas como pertenecientes a la clas positiva.
Falsos negativos (FN): Cantidad de instancias erroneamente clasificadas como negativas
Verdaderos negativos (VN): Cantiada de instancias correctamente clasificadas como clase negativa.

Exactitud: Proporcion de obs correctamente clasificadas
          exactitud = $\frac{VP + VN}{n}$ : Proporcion de obs correctamente clasificadas
          error = $\frac{FP+FN}{n}$  : Proprocion de obs erroneamente clasificadas
          sensibilidad = $\frac{VP}{VP+FN}$ : indica cuan apto es el clasificador para detectas aquellas obs a la clase positiva.
          especificidad = $\frac{VN}{VP+FP}$: indica cuan apto es el clasificador para detectas aquellas obs a la clase negativa.
          precision = $VPP = \frac{VP}{VP+FP}$: indica cuan exacta es la asignacion de elementos a la clase positiva.
          valor pred neg = $VPN = \frac{VN}{FN+VN}$ indica cuan exacta es la asignacion de elementos a la clase negativa.
          
Existe la curva ROC (Curva de calibracion): Que muestra la relacion entre la sensibilidad y la especidificada del modelo. Se representa por el area total bajo la curva ROC, llamado AUC que varia entre 0 y 1. Un clasificador perfecto es aque que tiene AUC = 1, y uno que no discrimina (no es mejor que aleatoreo) es AUC = 0,5.

## Ajuste de RLOG

  Existen varios criterios, pero hablaremos de los basados en parsimonia:
  AIC: Criterio de informacion de Akaike donde AIC = -2LL + 2k, con k numero de predictores.
  BIC: Criterio bayesiano de Schwarz ajusta la penalizacion a la compleijidad segun el tamano de la muestra. BIC = -2LL + 2k*ln(n)


## Regresion logistica en R.

```{r}
library(caret)
library(dplyr)
library(ggpubr)
library(pROC)

# Cargar y filtrar datos, teniendo cuidado de dejar
# Automatico como 2do nivel de la variable am para que
# sea considerada como la clase positiva.

datos <- mtcars |> filter(wt > 2 & wt < 5) |>
  mutate(am = factor(am, levels = c(1,0), labels = c("manual", "automatico")))

set.seed(101)
n <- nrow(datos)
i_muestra <- sample.int(n=n, size = floor(0.7*n), replace = FALSE)

# Dividir datos en conjunto de entrenamiento y prueba.
datos_ent <- datos[i_muestra, ]
datos_pru <- datos[-i_muestra, ]

# Ajustar modelo.
modelo <- glm(am ~ wt, family = binomial(link = "logit"), data = datos_ent)
print(summary(modelo))

# Evaluar el modelo con el conjunto de entrenamiento.
probs_ent <- fitted(modelo)

# Graficar curva ROC, indicando AUC obtenido.
ROC_ent <- roc(datos_ent[["am"]], probs_ent)
texto_ent <- sprintf("AUC = %.2f", ROC_ent[["auc"]])
g_roc_ent <- ggroc(ROC_ent, color = 2)
g_roc_ent <- g_roc_ent + geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), 
                                      linetype = "dashed")
g_roc_ent <- g_roc_ent + annotate("text", x = 0.3, y = 0.3, label = texto_ent)
g_roc_ent <- g_roc_ent + theme_pubr()
print(g_roc_ent)

# Obtener las predicciones.
umbral <- 0.5
preds_ent <- sapply(probs_ent, 
                    function(p) ifelse(p >= umbral, "automatico", "manual"))
preds_ent <- factor(preds_ent, levels = levels(datos[["am"]]))

# Obtener y mostrar estadísticas de clasificación en datos de entrenamiento.
mat_conf_ent <- confusionMatrix(preds_ent, datos_ent[["am"]], 
                                positive = "automatico")

cat("\n\nEvaluación del modelo (cjto. de entrenamiento):\n")
cat("-----------------------------------------------\n")
print(mat_conf_ent[["table"]])
cat("\n")
cat(sprintf("Exactitud: %.3f\n", mat_conf_ent[["overall"]][["Accuracy"]]))
cat(sprintf("Sensibilidad: %.3f\n", mat_conf_ent[["byClass"]][["Sensitivity"]]))
cat(sprintf("Especificidad: %.3f\n", mat_conf_ent[["byClass"]][["Specificity"]]))

# Evaluar el modelo con el conjunto de prueba.
probs_pru <- predict(modelo, datos_pru, type = "response")

# Graficar curva ROC, indicando AUC obtenido.
ROC_pru <- roc(datos_pru[["am"]], probs_pru)
texto_pru <- sprintf("AUC = %.2f", ROC_pru[["auc"]])
g_roc_pru <- ggroc(ROC_pru, color = 2)
g_roc_pru <- g_roc_pru + geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), 
                                      linetype = "dashed")
g_roc_pru <- g_roc_pru + annotate("text", x = 0.3, y = 0.3, label = texto_pru)
g_roc_pru <- g_roc_pru + theme_pubr()
print(g_roc_pru)

# Obtener las predicciones (con el mismo umbral).
preds_pru <- sapply(probs_pru, 
                    function(p) ifelse(p >= umbral, "automatico", "manual"))
preds_pru <- factor(preds_pru, levels = levels(datos[["am"]]))

# Obtener y mostrar estadísticas de clasificación en datos de prueba.
mat_conf_pru <- confusionMatrix(preds_pru, datos_pru[["am"]], 
                                positive = "automatico")

cat("\n\nEvaluación del modelo (cjto. de prueba):\n")
cat("-----------------------------------------\n")
print(mat_conf_pru[["table"]])
cat("\n")
cat(sprintf("Exactitud: %.3f\n", mat_conf_pru[["overall"]][["Accuracy"]]))
cat(sprintf("Sensibilidad: %.3f\n", mat_conf_pru[["byClass"]][["Sensitivity"]]))
cat(sprintf("Especificidad: %.3f\n", mat_conf_pru[["byClass"]][["Specificity"]]))
```

Ahora se reconstruira el modelo con la funcion train (cabe destacar que siempre se llega al mismo modelo).
```{r}
library(caret)
library(data.table)
library(dplyr)

datos <- mtcars |> filter(wt > 2 & wt < 5) |>
  mutate(am = factor(am, levels = c(1,0), labels = c("manual", "automatico")))

set.seed(101)
n <- nrow(datos)
i_muestra <- sample.int(n=n, size = floor(0.7*n), replace = FALSE)

# Dividir datos en conjunto de entrenamiento y prueba.
datos_ent <- datos[i_muestra, ]
datos_pru <- datos[-i_muestra, ]

modelo_ent <- train(am~wt, data = datos_ent, method = "glm",
                    family = binomial(link = "logit"),
                    trControl = trainControl(method = "cv", number = 4,
                                             savePredictions =TRUE))
modelo <- modelo_ent[["finalModel"]]

cat("Modelo RLog: \n")
cat("---------------\n")
print(summary(modelo))

# Obeter y mostrar estadisticas de clasificacion datos de entrenamiento.
mat_conf_ent <- confusionMatrix(modelo_ent[["pred"]][["pred"]],
                                modelo_ent[["pred"]][["obs"]],
                                positive = "automatico")
cat("\nEvaluacion del modelo cjto de entrenamiento: \n")
cat("-------------------------------------------\n")
print(mat_conf_ent[["table"]])
cat("\n")
cat(sprintf("    Exactitud: %.3f\n", mat_conf_ent[["overall"]][["Accuracy"]]))
cat(sprintf(" Sensibilidad: %.3f\n", mat_conf_ent[["byClass"]][["Sensitivity"]]))
cat(sprintf("Especificidad: %.3f\n", mat_conf_ent[["byClass"]][["Specificity"]]))

cat("\n\nDetalle por pliegue:\n")
cat("---------------------\n")
resumen <- data.table(modelo_ent[["resample"]][, c(1, 3)])
resumen <- rbind(resumen, list(modelo_ent[["results"]][[2]], "Mean"))
resumen <- rbind(resumen, list(modelo_ent[["results"]][[4]], "SD"))
print(resumen[1:4, ], row.names = FALSE)
cat("---------------------\n")
print(resumen[5:6, ], row.names = FALSE, col.names = "none", digits = 3)

# Obtener las predicciones en los datos de prueba.
umbral <- 0.5
probs <- predict(modelo, datos_pru, type = "response")
preds <- ifelse(probs >= umbral, "automatico", "manual")
preds <- factor(preds, levels = levels(datos[["am"]]))

# Obtener y mostrar estadísticas de clasificación en datos de entrenamiento.
mat_conf_pru <- confusionMatrix(preds, datos_pru[["am"]], positive = "automatico")

cat("\n\nEvaluación del modelo (cjto. de prueba):\n")
cat("-----------------------------------------\n")
print(mat_conf_pru[["table"]])
cat("\n")
cat(sprintf("Exactitud: %.3f\n", mat_conf_pru[["overall"]][["Accuracy"]]))
cat(sprintf("Sensibilidad: %.3f\n", mat_conf_pru[["byClass"]][["Sensitivity"]]))
cat(sprintf("Especificidad: %.3f\n", mat_conf_pru[["byClass"]][["Specificity"]]))

```


## Multiples predictores
Se puede hacer modificando la formula directamente, respuesta ~ pred_1 + pred_2

Con regresion paso a paso hacia adelente
```{r}
library(ggpubr)
library(dplyr)

# Imprimir mensajes de acvertencia a medida que ocurre.
opt <- options(warn = 1, width = 26)

# Cargar y filtrar datos
datos <- mtcars |> filter(wt >2 & wt < 5) |>
  select(-c("cyl","vs","gear","carb")) |>
  mutate(am = factor(am, levels = c(1,0) , labels = c("manual", "automatico")))

# Separar en entrenamiento y prueba

set.seed(101)
n <- nrow(datos)
i_muestra <- sample.int(n=n, size = floor(0.7*n), replace = FALSE)
datos_ent <- datos[i_muestra,]
datos_pru <- datos[-i_muestra,]

nulo <- glm(am ~ 1, family = binomial(link = "logit"), data = datos_ent)
maxi <- glm(am ~ ., family = binomial(link = "logit"), data = datos_ent)

cat("\nPaso 1:\n")
cat("-----\n")
print(add1(nulo, scope = maxi))

modelo1 <- update(nulo, .~. + wt)

cat("\nPaso 2: \n")
cat("---------\n")
print(add1(modelo1, scope = maxi))

modelo2 <- update(modelo1, .~.+mpg)

cat("\nPaso 3:\n")
cat("--------\n")
print(add1(modelo2,scope = maxi))

cat("Modelo conseguido con Regresion hacia adelante")
cat("-------------------------------\n")
print(summary(modelo2))

# Comparar modelos generados
cat("Comparar modelos generados")
cat("--------------------------------\n")

print(anova(nulo, modelo1, modelo2, test = "LRT"))

options(warn = opt[[1]], width = opt[[2]])


```

## Confiabilidad de un modelo RLog
Para una regresion logistica hay que cumplir las siguientes condiciones:
  1.- Debe existir una relacion lineal entre los predictores y la respuesta transformada
  2.- Los residuos deben ser independientes entre si

Otras condiciones que tambien se deben verificar
  3.- Multicolinealidad entre los predictores, que se aborda de la misma forma que RLM.
  4.- Informacion incompleta, que se produce cuando no contramos con obs suficientes para todas las posibles combinaciones de predictores, en especial para categoricas.
  5.- Separacion perfecta, que ocurre cuando no hay superposicione entre las clases, (cuando los predictores separan ambas clases completamente).
  
Y finalmente descartar la presencia de casos problematicos.
  6.- Las estimaciones de los coeficientes del modelo no estan dominadas por casos influyentes.

Resumen:
  1.- Se utiliza la funcion residualPlots del paquete car, con el argumento fitted = FALSE.  Tambien se utiliza la funcion crPlots(modelo) para residuos parciales.
  
  2.- Para esta condicion se utiliza durbinWatsonTest() del paquete car. Con esto se descarta que haya evidencia para sospechar que no se este cumpliendo la condicion de independencia de los residuos.
  
  3.- Para esta condicion se utiliza la funcion vif(modelo) y 1/vif(modelo), donde los umbrales criticos son 5 y 10. y para 1/vif es de 0.2
  
  4.- Se recomienda contar de 10 a 15 obs por cada predictor numerico y nivel de las variables categoricas.
  
  6.- Se utiliza la funcion influencePlot(modelo) del paquete car. 
    Casos problematicos:
      - Aquellos que tengan mas del doble de apalancamiento que el promedio
      - Aquellos que tengan un valor de distancia de Cook mayor a 1 o para muestras grandes de 2*p/n, con p cantidad de predictores y n cantidad de muestras.
